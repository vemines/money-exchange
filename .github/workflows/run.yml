name: Schedule Update

on:
  schedule:
    - cron: '0 * * * *' # Runs at the top of every hour
  workflow_dispatch: # Manual trigger supported

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      # Checkout code
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PAT }}

      # Set up Node.js
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      # Restore Git mtimes BEFORE running scripts
      - name: Restore Git modification times (pre-script)
        continue-on-error: true
        run: |
          echo "Restoring git mtimes..."
          git ls-files -z | \
            while IFS= read -r -d $'\0' file; do
              if [ -f "$file" ]; then
                ts=$(git log -1 --format=%ct -- "$file" 2>/dev/null)
                if [ -n "$ts" ]; then
                  formatted_time=$(date -u -d "@$ts" +'%Y%m%d%H%M.%S' 2>/dev/null)
                  if [ -n "$formatted_time" ]; then
                     touch -m -t "$formatted_time" "$file" 2>/dev/null
                  fi
                fi
              fi
            done
          echo "Pre-script mtime restoration complete."

      # Fetch latest currency data
      - name: Fetch Latest Currency Data
        id: fetch_data
        run: node index.js
        env:
          APPID: ${{ secrets.APPID }}

      # Cleanup old data (>5 years) from local ./data
      - name: Cleanup Old Data (> 5 years) from local ./data
        id: cleanup_data
        if: steps.fetch_data.outcome == 'success'
        run: |
          echo "Scanning for data older than 5 years in local ./data directory (based on filename) to delete..."

          cutoff_timestamp=$(TZ=UTC date -d "5 years ago" +%s)
          # Optional: echo "Cutoff timestamp (UTC, 5 years ago): $cutoff_timestamp ($(TZ=UTC date -d "@$cutoff_timestamp"))"

          if [ ! -d "./data" ]; then
            echo "./data directory not found. Nothing to clean."
            exit 0
          fi

          found_files_to_delete=false

          find "./data" -maxdepth 1 -type f -name '????-??-??.json' -print0 | while IFS= read -r -d $'\0' file; do
            filename=$(basename "$file")
            file_date_str="${filename%.json}"

            if [[ ! "$file_date_str" =~ ^[0-9]{4}-[0-9]{2}-[0-9]{2}$ ]]; then
              echo "Skipping file with unexpected name format: $filename"
              continue
            fi
            
            file_timestamp=$(TZ=UTC date -d "$file_date_str" +%s 2>/dev/null)
            
            if [ -z "$file_timestamp" ]; then
              echo "Warning: Could not parse date from filename: $filename. Skipping."
              continue
            fi

            if [ "$file_timestamp" -lt "$cutoff_timestamp" ]; then
              echo "DELETING old file: $file (Date: $file_date_str)"
              rm -f "$file"
              found_files_to_delete=true
            fi
          done || echo "Local cleanup script processing had warnings but continued."

          if [ "$found_files_to_delete" = false ]; then
            echo "No old files found to delete."
          fi

          echo "Local cleanup scan complete."

      # Generate history JSON files
      - name: Generate Historical Data
        id: generate_history
        if: steps.fetch_data.outcome == 'success' && steps.cleanup_data.outcome == 'success'
        run: node generate_history.js

      # Commit & push any changes back to the repo
      - name: Commit & Push Changes
        id: commit_changes
        if: steps.generate_history.outcome == 'success'
        run: |
          git config user.name 'github-actions[bot]'
          git config user.email 'github-actions[bot]@users.noreply.github.com'
          git add latest/ data/ history/ # Still add local data/ to git if it's part of your repo history
          if ! git diff --staged --quiet; then
            git commit -m "Update Currencies $(date -u +'%Y-%m-%dT%H:%M:%SZ')"
            git push https://x-access-token:${{ secrets.PAT }}@github.com/${{ github.repository }}
          else
            echo "No changes to commit."
          fi

      # Sync folders to Cloudflare R2
      - name: Sync to R2
        id: sync_latest_history_to_r2
        if: steps.generate_history.outcome == 'success'
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT_URL: https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
        run: |
          echo "Starting sync of 'latest' and 'history' to R2..."
          for DIR in latest history currencies; do
            if [ -d "$DIR" ]; then
              echo " → Syncing $DIR/"
              aws s3 sync "./$DIR/" "s3://${R2_BUCKET_NAME}/${DIR}/" \
                --endpoint-url "${R2_ENDPOINT_URL}" \
                --acl public-read \
                --delete \
                --no-progress
            else
              echo " → Directory $DIR/ not found; skipping."
            fi
          done
          echo "'latest' and 'history' R2 sync complete."
