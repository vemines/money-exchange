name: Schedule Update

on:
  schedule:
    - cron: '0 * * * *' # Runs at the top of every hour
  workflow_dispatch: # Manual trigger supported

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      # Checkout code
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PAT }}
          fetch-depth: 0 # Need full history for git diff

      # Save the current HEAD so we can diff later
      - name: Save initial HEAD
        id: save_head
        run: echo "prev_head=$(git rev-parse HEAD)" >> $GITHUB_OUTPUT

      # Set up Node.js
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      # Fetch latest currency data
      - name: Fetch Latest Currency Data
        id: fetch_data
        run: node index.js
        env:
          APPID: ${{ secrets.APPID }}

      # Generate history JSON files
      - name: Generate Historical Data
        id: generate_history
        if: steps.fetch_data.outcome == 'success'
        run: node generate_history.js

      # Commit & push any changes back to the repo
      - name: Commit & Push Changes
        id: commit_changes
        if: steps.generate_history.outcome == 'success'
        run: |
          git config user.name 'github-actions[bot]'
          git config user.email 'github-actions[bot]@users.noreply.github.com'
          git add latest/ data/ history/
          if ! git diff --staged --quiet; then
            git commit -m "Update Currencies $(date -u +'%Y-%m-%dT%H:%M:%SZ')"
            git push https://x-access-token:${{ secrets.PAT }}@github.com/${{ github.repository }}
            echo "committed=true" >> $GITHUB_OUTPUT
          else
            echo "No changes to commit."
            echo "committed=false" >> $GITHUB_OUTPUT
          fi

      # Upload only changed files to R2 (avoid full re-upload)
      - name: Upload changed files to R2
        id: sync_to_r2
        if: steps.generate_history.outcome == 'success'
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT_URL: https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
        run: |
          set -euo pipefail
          echo "Preparing list of changed files to upload..."

          PREV="${{ steps.save_head.outputs.prev_head }}"
          CUR="$(git rev-parse HEAD)"
          COMMITTED="${{ steps.commit_changes.outputs.committed }}"

          echo "Previous HEAD: $PREV"
          echo "Current  HEAD: $CUR"
          echo "New commit made: $COMMITTED"

          # Determine changed files based on whether we made a commit
          if [ "$COMMITTED" = "true" ] && [ "$PREV" != "$CUR" ]; then
            echo "Detecting files changed between $PREV and $CUR"
            CHANGED_FILES=$(git diff --name-only "$PREV" "$CUR" 2>/dev/null || echo "")
          else
            echo "No new commit made; checking for any staged/unstaged changes in target folders"
            # Check for any changes in our target directories
            CHANGED_FILES=""
            for DIR in latest data history currencies; do
              if [ -d "$DIR" ]; then
                # Get any modified files in this directory (including untracked)
                DIR_CHANGES=$(git status --porcelain "$DIR" 2>/dev/null | awk '{print $2}' || echo "")
                if [ -n "$DIR_CHANGES" ]; then
                  CHANGED_FILES="$CHANGED_FILES"$'\n'"$DIR_CHANGES"
                fi
              fi
            done
          fi

          # Clean up the changed files list (remove empty lines)
          CHANGED_FILES=$(echo "$CHANGED_FILES" | grep -v '^$' || echo "")

          echo "Changed files detected:"
          echo "$CHANGED_FILES"

          # If no changes detected, ensure latest/data.json exists (fallback safety upload)
          if [ -z "$CHANGED_FILES" ]; then
            echo "No changed files detected. Ensuring latest/data.json is present on R2."
            if [ -f "latest/data.json" ]; then
              echo "Uploading latest/data.json as safety check..."
              aws s3 cp "latest/data.json" "s3://${R2_BUCKET_NAME}/latest/data.json" \
                --endpoint-url "${R2_ENDPOINT_URL}" \
                --acl public-read \
                --content-type "application/json" \
                --no-progress || echo "Safety upload failed, but continuing..."
            else
              echo "latest/data.json not found locally; skipping safety upload."
            fi
            echo "R2 upload complete (no changes detected)."
            exit 0
          fi

          # Upload only files in our target directories
          uploaded_count=0
          echo "$CHANGED_FILES" | while IFS= read -r file; do
            # Skip empty lines
            [ -z "$file" ] && continue

            case "$file" in
              latest/*|data/*|history/*|currencies/*)
                if [ -f "$file" ]; then
                  echo "üì§ Uploading: $file -> s3://${R2_BUCKET_NAME}/${file}"
                  
                  # Determine content type based on file extension
                  case "$file" in
                    *.json) CONTENT_TYPE="application/json" ;;
                    *.html) CONTENT_TYPE="text/html" ;;
                    *.css)  CONTENT_TYPE="text/css" ;;
                    *.js)   CONTENT_TYPE="application/javascript" ;;
                    *)      CONTENT_TYPE="application/octet-stream" ;;
                  esac
                  
                  if aws s3 cp "$file" "s3://${R2_BUCKET_NAME}/${file}" \
                    --endpoint-url "${R2_ENDPOINT_URL}" \
                    --acl public-read \
                    --content-type "$CONTENT_TYPE" \
                    --no-progress; then
                    uploaded_count=$((uploaded_count + 1))
                  else
                    echo "‚ùå Upload failed for $file"
                  fi
                else
                  echo "‚ö†Ô∏è  Local file $file not found (may have been deleted) ‚Äî skipping remote delete to preserve history."
                fi
                ;;
              *)
                echo "‚è≠Ô∏è  Skipping unrelated file: $file"
                ;;
            esac
          done

          echo "‚úÖ R2 upload complete. Files uploaded: $uploaded_count"
