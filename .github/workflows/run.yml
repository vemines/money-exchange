name: Schedule Update

on:
  schedule:
    - cron: '0 * * * *'
  workflow_dispatch:

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PAT }} # PAT for pushing changes back to the repo

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Fetch Latest Currency Data
        id: fetch_data
        run: node index.js
        env:
          APIURL: ${{ secrets.APIURL }}
        continue-on-error: false

      - name: Cleanup Old Data (> 5 years)
        id: cleanup_data
        if: steps.fetch_data.outcome == 'success'
        run: |
          TARGET_DIR="./data"
          DAYS_OLD=1825 # Files older than approx 5 years
          echo "Cleaning up files older than $DAYS_OLD days in $TARGET_DIR..."
          # Find and delete files matching pattern and age, logging each deletion
          find "$TARGET_DIR" -maxdepth 1 -type f -name '????-??-??.json' -mtime +$DAYS_OLD -print0 | while IFS= read -r -d $'\0' file; do
            echo "Deleting old file: $file (Last modified: $(stat -c %y "$file"))"
            rm -f "$file" || echo "Warning: Failed to delete $file"
          done
          echo "Cleanup complete. Remaining JSON files in $TARGET_DIR: $(find "$TARGET_DIR" -maxdepth 1 -type f -name '????-??-??.json' | wc -l)"

      - name: Generate Historical Data
        id: generate_history
        if: steps.fetch_data.outcome == 'success' && steps.cleanup_data.outcome == 'success'
        run: node generate_history.js

      - name: Commit and push changes
        id: commit_changes
        if: steps.fetch_data.outcome == 'success' && steps.cleanup_data.outcome == 'success' && steps.generate_history.outcome == 'success'
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add latest/ data/ history/
          if ! git diff --staged --quiet; then
            COMMIT_MSG="Update Currencies $(date -u +'%Y-%m-%d T %H-%M-%S UTC')"
            git commit -m "$COMMIT_MSG"
            git push https://x-access-token:${{ secrets.PAT }}@github.com/${{ github.repository }}
          else
            echo "No changes detected in currency data to commit."
          fi

      - name: Install AWS CLI
        if: steps.fetch_data.outcome == 'success' && steps.cleanup_data.outcome == 'success' && steps.generate_history.outcome == 'success'
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y -qq awscli

      - name: Upload data to Cloudflare R2
        if: steps.fetch_data.outcome == 'success' && steps.cleanup_data.outcome == 'success' && steps.generate_history.outcome == 'success'
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT_URL: https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
        run: |
          DIRECTORIES_TO_SYNC="latest data history"
          for DIR_NAME in $DIRECTORIES_TO_SYNC; do
            if [ -d "./$DIR_NAME" ]; then
              echo "Syncing './$DIR_NAME/' to R2 bucket '$R2_BUCKET_NAME' under '$DIR_NAME/'..."
              aws s3 sync "./$DIR_NAME/" "s3://${R2_BUCKET_NAME}/${DIR_NAME}/" \
                --endpoint-url "${R2_ENDPOINT_URL}" \
                --acl public-read \
                --delete # Removes files from R2 not present locally
            else
              echo "Directory './$DIR_NAME' not found. Skipping sync for this directory."
            fi
          done
          echo "R2 upload process complete."
